<!DOCTYPE html>
<script src="https://www.baihan.nyc/js/loadhtml.js"></script>

<html lang="en">

<head>
    <div w3-include-html="https://www.baihan.nyc/html/header.html"></div>
    <script> w3IncludeHTML(); </script>
</head>

<body>
    <div w3-include-html="https://www.baihan.nyc/html/navleft.html"></div>
    <div w3-include-html="https://www.baihan.nyc/html/navright.html"></div>
    <script> w3IncludeHTML(); </script>

    <div class="container-fluid p-0">
        <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="">
            <div class="my-auto">
                <h2 class="mb-5" style="text-transform:none">Reinforcement Learning Agents with Mental Disorders</h2>

                <b class="text-primary">  by Baihan Lin, Columbia University, Sep 2018 &nbsp; </b>
                <p class="mb-5 text-primary">
                    <br> <b> GitHub code:</b> <a href="https://github.com/doerlbh/mentalRL" style="color:#268fd6">https://github.com/doerlbh/mentalRL</a>

                    <br>
                    <br> Joint work with Dr. Guillermo Cecchi (IBM Research), Dr. Djallel Bouneffouf (IBM Research), Dr. Jenna Reinen (IBM Research) and Dr. Irina Rish (Mila, UdeM)
                    <br>
                </p>

                <h3 style="text-transform:none"> TL;DR </h3>

                <p class="text-primary">
                    I train AI agents to play games just like people with mental disorders play games, which can (1) help neuroscientists understand these conditions, (2) help create better AI algorithms to tackle human-level challenges, and (3) help doctors clinically monitor psychiatric patients by simply letting them play computer games.
                    <br>
                    <br>

                </p>
                <img src="./img/mentalRL.png" alt="" style="width:80%;display:block;margin-left:auto;margin-right:auto;">
                <br>

                <h3 style="text-transform:none"> Abstract </h3>

                <p class="mb-5 text-primary">
                    Drawing an inspiration from behavioral studies of human decision making, we propose here a more general and flexible parametric framework for reinforcement learning that extends standard Q-learning to a two-stream model for processing positive and negative rewards, and allows to incorporate a wide range of reward-processing biases -- an important component of human decision making which can help us better understand a wide spectrum of multi-agent interactions in complex real-world socioeconomic systems, as well as various neuropsychiatric conditions associated with disruptions in normal reward processing. From the computational perspective, we observe that the proposed Split-QL model and its clinically inspired variants consistently outperform standard Q-Learning and SARSA methods, as well as recently proposed Double Q-Learning approaches, on simulated tasks with particular reward distributions, a real-world dataset capturing human decision-making in gambling tasks, and the Pac-Man game in a lifelong learning setting across different reward stationarities.
                    <br>
                    <!-- <img src="../../img/random/sleep.jpg" alt="" class="photo"> -->
                </p>

                <h3 style="text-transform:none"> Publications </h3>

                <p class="mb-5 text-primary">
                    [1] Lin, B., Bouneffouf, D., & Cecchi, G. (2019). Split Q learning: reinforcement learning with two-stream rewards. <em> In Proceedings of the 28th International Joint Conference on Artificial Intelligence (pp. 6448-6449). AAAI Press.</em>
                    <br> <b> link: </b> <a href="https://arxiv.org/abs/1906.12350" style="color:#268fd6">https://arxiv.org/abs/1906.12350</a>
                    <br>
                    <br> [2] Lin, B., Cecchi, G., Bouneffouf, D., Reinen, J., & Rish, I. (2019). Reinforcement Learning Models of Human Behavior: Reward Processing in Mental Disorders. <em> 2019 NeurIPS Workshop on Biological and Artificial Reinforcement Learning (BARL) </em>
                    <br> <b> link: </b> <a href="https://arxiv.org/abs/1906.11286" style="color:#268fd6">https://arxiv.org/abs/1906.11286</a>
                    <br>
                    <br> [3] Lin, B. (2019). Modeling Neurological and Psychiatric Disorders with Reward Biased Reinforcement Learning Models. <em> 2019 Technology in Psychiatry Summit (TIPS) </em>
                    <!-- <img src="../../img/random/sleep.jpg" alt=""> -->
                </p>

                <h3 style="text-transform:none"> Method </h3>

                <p class="mb-5 text-primary">
                    Inspired by the neurological and psychiatric literature, we build upon the standard Q-Learning, a state-of-art approach to reinforcement learning problem, and extend it to a parametric family of models, called Split-QL, where the reward information is split into two streams, positive and negative. The model puts different weight parameters on the incoming positive and negative rewards, and imposes different discounting factors on positive and negative reward accumulated in the past. This simple but powerful extension of Q-learning allows to capture a variety of reward-processing biases observed in human behavior. Below is our algorithm and parameters:
                    <br>
                    <img src="./img/algorithm.png" alt=""  style="width:80%;display:block;margin-left:auto;margin-right:auto;">
                </p>

                <h3 style="text-transform:none"> Results </h3>

                <p class="mb-5 text-primary">

                    Empirically, I evaluated the algorithms in three settings: the gambling game of a simple Markov Decision Process (MDP), a real-life Iowa Gambling Task (IGT) and the PacMan computer game with different stationarities.
                    <br> In the MDP and IGT tasks, our algorithms outperform baseline in many cases.
                    <br>
                    <img src="./img/f1.png" alt=""  style="width:80%;display:block;margin-left:auto;margin-right:auto;">
                    <br> For instance, in 100 randomly generated arficial environments, our agents beats standard ones most of the times
                    <br>
                    <img src="./img/f2.png" alt=""  style="width:80%;display:block;margin-left:auto;margin-right:auto;">
                    <br> In the IGT experiment, the behavioral trajectories of the "mental" agents cluster by the psychiatric conditions with real human data.
                    <br>
                    <img src="./img/f3.png" alt=""  style="width:80%;display:block;margin-left:auto;margin-right:auto;">
                    <br> In the PacMan experiment, our two-stream-reward paradigm demonstrated constant advantages over the baseline algorithms.
                    <br>
                    <img src="./img/f4.png" alt=""  style="width:100%;display:block;margin-left:auto;margin-right:auto;">
                </p>

                <h3 style="text-transform:none"> Ongoing work </h3>

                <p class="mb-5 text-primary">
                    As an extension, I am building a smartphone app to let user play a game for a few rounds and reveals his/her clinical tendency to a spectrum of psychiatric diseases -- a easy and fun way to diagnose and monitor mental health conditions for patients. Stay tuned!
                    <br>
                    <!-- <img src="../../img/random/sleep.jpg" alt="" class="photo"> -->
                </p>

                <h3 style="text-transform:none"> Watch some "mental" agents playing PacMan </h3>

                <div class="photorow">
                    <div class="photocolumn">
                        <div class="simplecontainer">
                            <img src="./img/AZ.gif" alt="" class="photo">
                            <div class="overlay"> Alzheimer's </div>
                        </div>
                        <div class="simplecontainer">
                            <img src="./img/ADD.gif" alt="" class="photo">
                            <div class="overlay"> Addiction </div>
                        </div>
                        <div class="simplecontainer">
                            <img src="./img/ADHD.gif" alt="" class="photo">
                            <div class="overlay"> ADHD </div>
                        </div>
                        <div class="simplecontainer">
                            <img src="./img/bvFTD.gif" alt="" class="photo">
                            <div class="overlay"> bvFTD (dementia) </div>
                        </div>
                    </div>
                    <div class="photocolumn">
                        <div class="simplecontainer">
                            <img src="./img/CP.gif" alt="" class="photo">
                            <div class="overlay"> Chronic pain </div>
                        </div>
                        <div class="simplecontainer">
                            <img src="./img/DQL.gif" alt="" class="photo">
                            <div class="overlay"> Double Q-Learning </div>
                        </div>
                        <div class="simplecontainer">
                            <img src="./img/M.gif" alt="" class="photo">
                            <div class="overlay"> moderate </div>
                        </div>
                        <div class="simplecontainer">
                            <img src="./img/NQL.gif" alt="" class="photo">
                            <div class="overlay"> Negative Q-Learning </div>
                        </div>
                    </div>
                    <div class="photocolumn">
                        <div class="simplecontainer">
                            <img src="./img/PD.gif" alt="" class="photo">
                            <div class="overlay"> Parkinson's </div>
                        </div>
                        <div class="simplecontainer">
                            <img src="./img/PQL.gif" alt="" class="photo">
                            <div class="overlay"> Positive Q-Learning </div>
                        </div>
                        <div class="simplecontainer">
                            <img src="./img/QL.gif" alt="" class="photo">
                            <div class="overlay"> Q-Learning </div>
                        </div>
                        <div class="simplecontainer">
                            <img src="./img/SQL.gif" alt="" class="photo">
                            <div class="overlay"> Split Q-Learning </div>
                        </div>

                    </div>
                </div>

            </div>
        </section>
    </div>

    <div w3-include-html="https://www.baihan.nyc/html/bodyjs.html"></div>
    <script> w3IncludeHTML(); </script>
    
</body>

    <div w3-include-html="https://www.baihan.nyc/html/footer.html"></div>
    <script> w3IncludeHTML(); </script>

</html>